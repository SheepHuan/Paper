# NeRF 

## 简述NeRF流程
NeRF去构建出一个3D场景主要通过训练和推理两个部分。
1. [Camera paramertes] 在准备好一组拍摄的2D图像后，首先解算每张图像对应的相机位姿参数。这一步可以使用如COLMAP等现成工具。COLMAP 会匹配不同图像中出现的场景共同点来计算相机位姿。此外我们假设整个场景位于范围是$[-1,1]^3$的立方体盒子内。
2. [3D point sampling] 对一张真实图像，从相机发出一条光线，光线穿过图像进入场景。光线和图像的交点$p$的像素值$I(p)$是基准颜色。我们在这条光线上离散采样得到若干个点。把这些采样点的空间坐标$[x,y,z]$和第一步解算出的对应的相机的姿态$(\theta,\phi)$组合起来作为神经网络的输入。
3. [NeRF model] 通过神经网络预测光线上每个采样点的颜色和密度。
4. [Rendering] 通过**体渲染**，我们可以用上一步神经网络输出的采样点的颜色和密度作离散和，近似计算对应光线的像素值$\hat{I}(p)$。
5. [Photometric loss] 把$\hat{I}(p)$和光线颜色的真值$I(p)$比较计算误差和梯度，就可以对神经网络进行训练。


## 什么是体渲染



## Instant NGP (Nvidia)



## MobileNeRF (Google)